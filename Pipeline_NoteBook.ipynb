{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aws_sklearn_split_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aws_sklearn_split_data.py \n",
    "import datetime\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)\n",
    "\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket='hamzatestbucket', Key='original_data/testsensor6_all.csv')\n",
    "\n",
    "data = pd.read_csv(obj['Body']) # 'Body' is a key word\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "train = data[:-3]\n",
    "deploy_test = data[-3:]\n",
    "\n",
    "train.to_csv('train.csv')\n",
    "deploy_test.to_csv('deploy_test.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-ap-southeast-2-819846678795\r\n"
     ]
    }
   ],
   "source": [
    "!python aws_sklearn_split_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aws_sklearn_upload_train_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aws_sklearn_upload_train_data.py\n",
    "\n",
    "import boto3\n",
    "bucket = 'sagemaker-learning-to-deploy-scikitlearn-hamza'\n",
    "region = 'ap-southeast-2'\n",
    "s3_session = boto3.Session().resource('s3')\n",
    "s3_session.create_bucket(Bucket=bucket, \n",
    "                         CreateBucketConfiguration=\n",
    "                         {'LocationConstraint': region})\n",
    "s3_session.Bucket(bucket).Object('train/train.csv').upload_file('train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"aws_sklearn_upload_train_data.py\", line 8, in <module>\r\n",
      "    {'LocationConstraint': region})\r\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/resources/factory.py\", line 520, in do_action\r\n",
      "    response = action(self, *args, **kwargs)\r\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/resources/action.py\", line 83, in __call__\r\n",
      "    response = getattr(parent.meta.client, operation_name)(*args, **params)\r\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\", line 357, in _api_call\r\n",
      "    return self._make_api_call(operation_name, kwargs)\r\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\", line 676, in _make_api_call\r\n",
      "    raise error_class(parsed_response, operation_name)\r\n",
      "botocore.errorfactory.BucketAlreadyOwnedByYou: An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\r\n"
     ]
    }
   ],
   "source": [
    "!python aws_sklearn_upload_train_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aws_sklearn_training_draft.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aws_sklearn_training_draft.py\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from matplotlib import pyplot as PLT\n",
    "from matplotlib.pyplot import cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO, BytesIO # python3;  BytesIO for images StringIO for files\n",
    "import boto3\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    # Create a parser object to collect the environment variables that are in the\n",
    "    # default AWS Scikit-learn Docker container.\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Load data from the location specified by args.train (In this case, an S3 bucket).\n",
    "    data = pd.read_csv(os.path.join(args.train,'train.csv'), engine=\"python\")\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    X = data[['SiPM1','SiPM2','SiPM3','SiPM4','SiPM5','SiPM6']]\n",
    "    y = data[['X','Y']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "    \n",
    "    # train\n",
    "    print('training model')\n",
    "    model = XGBRegressor(objective='reg:squarederror', learning_rate=0.2) \n",
    "    model = MultiOutputRegressor(model, n_jobs=-1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print abs error\n",
    "    print('validating model')\n",
    "    abs_err = np.sqrt(mse(y_test, model.predict(X_test)))\n",
    "    \n",
    "    # print couple perf metrics\n",
    "    for q in [10, 50, 90]:\n",
    "        print('AE-at-' + str(q) + 'th-percentile: '\n",
    "              + str(np.percentile(a=abs_err, q=q)))\n",
    "        \n",
    "    pred = model.predict(X_test)\n",
    "    rmse_manual = (abs(pred - y_test)**2)\n",
    "    print(rmse_manual.shape)\n",
    "    rmse_manual = rmse_manual.iloc[:,0] + rmse_manual.iloc[:,1]\n",
    "    print(rmse_manual)\n",
    "    \n",
    "    \n",
    "    x = y_test.iloc[:,0]\n",
    "    y = y_test.iloc[:,1]\n",
    "    z = np.sqrt(rmse_manual)\n",
    "    c = pd.concat([y_test, z.rename('RMSE')], ignore_index = False, axis=1) #This is for exporting the csv\n",
    "    print(c)\n",
    "\n",
    "    PLT.show() \n",
    "    \n",
    "    gridsize=100\n",
    "    PLT.figure(figsize=(10, 8 ))\n",
    "    PLT.subplot(111)\n",
    "    PLT.xlabel(\"X\")\n",
    "    PLT.ylabel(\"Y\")\n",
    "    PLT.title(\"SENSOR 6 RMSE HEATMAP\")\n",
    "\n",
    "    PLT.hexbin(x, y, C=z, gridsize=gridsize, cmap=cm.rainbow, reduce_C_function= np.mean, bins='log')\n",
    "\n",
    "    PLT.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "\n",
    "    cb = PLT.colorbar( )\n",
    "    cb.set_label('RMSE')\n",
    "\n",
    "\n",
    "\n",
    "    PLT.show() \n",
    "\n",
    "    \n",
    "    img_data = BytesIO() #This is for images\n",
    "    PLT.savefig(img_data, format='png')\n",
    "    bucket = 'sagemaker-learning-to-deploy-scikitlearn-hamza'# already created on S3\n",
    "    img_data.seek(0)\n",
    "    image = img_data.read()\n",
    "\n",
    "\n",
    "    # put the image into S3\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Object(bucket, 'predictions/results.png').put(ACL='public-read', Body=image)\n",
    "\n",
    "\n",
    "    \n",
    "    csv_buffer = StringIO()\n",
    "    c.to_csv(csv_buffer)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object(bucket, 'predictions/results.csv').put(Body=csv_buffer.getvalue())\n",
    "        \n",
    "    pickle.dump(model, open(os.path.join(args.model_dir, \"model.joblib\"), 'wb'))\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \n",
    "    model = pickle.load(open(os.path.join(model_dir, \"model.joblib\"), 'rb'))\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'text/csv':\n",
    "        samples = []\n",
    "        for r in request_body.split('|'):\n",
    "            samples.append(list(map(float,r.split(','))))\n",
    "        return np.array(samples)\n",
    "    else:\n",
    "        raise ValueError(\"Thie model only supports text/csv input\")\n",
    "        \n",
    "        \n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpuwjmtz1k_algo-1-ugj0v_1 ... \n",
      "\u001b[1BAttaching to tmpuwjmtz1k_algo-1-ugj0v_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker_xgboost_container.training:Invoking user training script.\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:Module aws_sklearn_training_draft does not provide a setup.py. \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:Generating setup.cfg\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:Generating MANIFEST.in\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:Installing module with the following command:\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Building wheels for collected packages: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m   Building wheel for aws-sklearn-training-draft (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \u001b[?25h  Created wheel for aws-sklearn-training-draft: filename=aws_sklearn_training_draft-1.0.0-py2.py3-none-any.whl size=6694 sha256=4d4edba5c5dc3c0557aaff172274dffdce7d43c6ddcbcc589de256c634a34d49\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-0tqi4d5x/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Successfully built aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Installing collected packages: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Successfully installed aws-sklearn-training-draft-1.0.0\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m INFO:sagemaker-containers:Invoking user script\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"current_host\": \"algo-1-ugj0v\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         \"algo-1-ugj0v\"\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"job_name\": \"sagemaker-xgboost-2020-11-17-05-39-47-539\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"master_hostname\": \"algo-1-ugj0v\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-southeast-2-819846678795/sagemaker-xgboost-2020-11-17-05-39-47-539/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"module_name\": \"aws_sklearn_training_draft\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         \"current_host\": \"algo-1-ugj0v\",\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m             \"algo-1-ugj0v\"\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m     \"user_entry_point\": \"aws_sklearn_training_draft.py\"\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_HOSTS=[\"algo-1-ugj0v\"]\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_USER_ENTRY_POINT=aws_sklearn_training_draft.py\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ugj0v\",\"hosts\":[\"algo-1-ugj0v\"]}\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_CURRENT_HOST=algo-1-ugj0v\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_MODULE_NAME=aws_sklearn_training_draft\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-southeast-2-819846678795/sagemaker-xgboost-2020-11-17-05-39-47-539/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-ugj0v\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1-ugj0v\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2020-11-17-05-39-47-539\",\"log_level\":20,\"master_hostname\":\"algo-1-ugj0v\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-819846678795/sagemaker-xgboost-2020-11-17-05-39-47-539/source/sourcedir.tar.gz\",\"module_name\":\"aws_sklearn_training_draft\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ugj0v\",\"hosts\":[\"algo-1-ugj0v\"]},\"user_entry_point\":\"aws_sklearn_training_draft.py\"}\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m /miniconda3/bin/python -m aws_sklearn_training_draft\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m training model\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m validating model\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m AE-at-10th-percentile: 18.25183486796955\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m AE-at-50th-percentile: 18.25183486796955\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m AE-at-90th-percentile: 18.25183486796955\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m (47016, 2)\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 39714      166.512306\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 57595      859.357645\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 104385      21.746982\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 30196      716.618996\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 15951      181.158605\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m              ...     \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 110123    2234.532322\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 102521     812.568891\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 80595        8.342384\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 20484      297.536061\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 68927        2.079697\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m Length: 47016, dtype: float64\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m                X  ...       RMSE\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 39714   23.76390  ...  12.903965\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 57595  -73.21300  ...  29.314802\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 104385   5.19056  ...   4.663366\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 30196  -52.06580  ...  26.769740\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 15951  -28.63590  ...  13.459517\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m ...          ...  ...        ...\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 110123 -14.12670  ...  47.270840\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 102521 -74.45320  ...  28.505594\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 80595   -4.79258  ...   2.888318\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 20484  -69.57740  ...  17.249234\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m 68927  -72.70370  ...   1.442115\n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ugj0v_1  |\u001b[0m [47016 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmpuwjmtz1k_algo-1-ugj0v_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "role = 'AmazonSageMaker-ExecutionRole-20201012T123014'\n",
    "\n",
    "# Create the XGBoost Object by directing it to the aws_sklearn_main.py script\n",
    "aws_sklearn = XGBoost(entry_point='aws_sklearn_training_draft.py',\n",
    "                      train_instance_type='local',\n",
    "                      role=role,\n",
    "                     framework_version= '1.0-1',\n",
    "                     train_instance_count = 1)\n",
    "\n",
    "# Train the model using by passing the path to the S3 bucket with the training data\n",
    "aws_sklearn.fit({'train': 's3://sagemaker-learning-to-deploy-scikitlearn-hamza/train'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpoib75ixz_algo-1-1ny1n_1\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] nginx config: \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m worker_processes auto;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m daemon off;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m events {\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m http {\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   server {\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     location / {\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   }\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] Module aws_sklearn_training_draft does not provide a setup.py. \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] Generating setup.cfg\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] Generating MANIFEST.in\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:48:INFO] Installing module with the following command:\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Building wheels for collected packages: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   Building wheel for aws-sklearn-training-draft (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \u001b[?25h  Created wheel for aws-sklearn-training-draft: filename=aws_sklearn_training_draft-1.0.0-py2.py3-none-any.whl size=6694 sha256=da13b3b42bfaaa5baf35ea1292d4323c275451a553adb2e991a1ff1cd9013425\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-wd0cedt_/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Successfully built aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Installing collected packages: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Successfully installed aws-sklearn-training-draft-1.0.0\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:50:INFO] Generating new fontManager, this may take some time...\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m 2020/11/17 05:41:50 [crit] 17#17: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m 172.18.0.1 - - [17/Nov/2020:05:41:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17 05:41:51 +0000] [33] [INFO] Starting gunicorn 19.10.0\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17 05:41:51 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17 05:41:51 +0000] [33] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17 05:41:51 +0000] [36] [INFO] Booting worker with pid: 36\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17 05:41:51 +0000] [37] [INFO] Booting worker with pid: 37\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:55:INFO] No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m [2020-11-17:05:41:55:INFO] Installing module with the following command:\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Building wheels for collected packages: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   Building wheel for aws-sklearn-training-draft (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m \u001b[?25h  Created wheel for aws-sklearn-training-draft: filename=aws_sklearn_training_draft-1.0.0-py2.py3-none-any.whl size=6694 sha256=fe1ddefb04bc24da07a80bf784bb49a04f1c134446ba98ebdc9fa67c7f93974b\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-etgzt5bc/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Successfully built aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Installing collected packages: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m   Attempting uninstall: aws-sklearn-training-draft\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     Found existing installation: aws-sklearn-training-draft 1.0.0\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m     Uninstalling aws-sklearn-training-draft-1.0.0:\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m       Successfully uninstalled aws-sklearn-training-draft-1.0.0\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m Successfully installed aws-sklearn-training-draft-1.0.0\n",
      "!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m 172.18.0.1 - - [17/Nov/2020:05:41:57 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\r\n",
      "sagemaker-xgboost-2020-11-17-05-41-43-352\n"
     ]
    }
   ],
   "source": [
    "# Deploy model\n",
    "aws_sklearn_predictor = aws_sklearn.deploy(instance_type='local', \n",
    "                                           initial_instance_count=1)\n",
    "\n",
    "# Print the endpoint to test in next step\n",
    "print(aws_sklearn_predictor.endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103,177,120,236,123,141|134,337,83,106,141,146|355,345,326,376,340,423\n",
      "[['-17.505434', '-73.20314'], ['76.36983', '-86.70647'], ['2.8188188', '1.1041712']]\n",
      "\u001b[36malgo-1-1ny1n_1  |\u001b[0m 172.18.0.1 - - [17/Nov/2020:05:48:19 +0000] \"POST /invocations HTTP/1.1\" 200 60 \"-\" \"-\"\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "aws_sklearn_predictor.serializer = csv_serializer\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load in the deploy_test data\n",
    "deploy_test = pd.read_csv(\"deploy_test.csv\", header= None).iloc[1:,1:]\n",
    "deploy_test = deploy_test.values.tolist()\n",
    "\n",
    "# Format the deploy_test data features\n",
    "request_body = \"\"\n",
    "for sample in deploy_test:\n",
    "    request_body += \",\".join([str(n) for n in sample[2:]]) + \"|\"\n",
    "\n",
    "request_body = request_body[:-1]\n",
    "print(request_body)\n",
    "prediction = aws_sklearn_predictor.predict(request_body)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aws_sklearn_predictor.delete_model()\n",
    "aws_sklearn_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(prediction)\n",
    "a = pd.DataFrame(a[:,:], columns = ['pred_X','pred_Y']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_X</th>\n",
       "      <th>pred_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.505434</td>\n",
       "      <td>-73.203140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.369830</td>\n",
       "      <td>-86.706470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.818819</td>\n",
       "      <td>1.104171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_X     pred_Y\n",
       "0 -17.505434 -73.203140\n",
       "1  76.369830 -86.706470\n",
       "2   2.818819   1.104171"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
